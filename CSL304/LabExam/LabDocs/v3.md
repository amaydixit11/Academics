# AI Lab Exam - Comprehensive Cheatsheet

## üì¶ SETUP & LIBRARIES

### Essential Imports
```python
# Basic imports (always include these)
import random
import math
import copy
from typing import Tuple, List
from heapq import heappush, heappop
import heapq
from collections import deque
import time

# For visualization (if needed)
import networkx as nx
import matplotlib.pyplot as plt
import pandas as pd
```

### Installation Commands
```bash
pip install networkx matplotlib numpy pandas
```

---

## üß© 1. 8-PUZZLE PROBLEM

### Key Concepts
- **Goal State**: `[[1,2,3], [4,5,6], [7,8,0]]` (0 = blank)
- **Moves**: UP, DOWN, LEFT, RIGHT (move blank space)
- **Heuristic**: Manhattan Distance

### Complete A* Implementation
```python
goal = [[1, 2, 3], [4, 5, 6], [7, 8, 0]]
moves = {'UP': (-1, 0), 'DOWN': (1, 0), 'LEFT': (0, -1), 'RIGHT': (0, 1)}

def flatten(state):
    return [num for row in state for num in row]

def is_solvable(state):
    """Check if puzzle is solvable - count inversions"""
    l = [num for num in flatten(state) if num != 0]
    inversions = sum(1 for i in range(len(l)) for j in range(i+1, len(l)) if l[i] > l[j])
    return inversions % 2 == 0

def manhattan_distance(state):
    """Heuristic: sum of distances from goal position"""
    distance = 0
    for i in range(3):
        for j in range(3):
            val = state[i][j]
            if val != 0:
                goal_x, goal_y = divmod(val - 1, 3)
                distance += abs(i - goal_x) + abs(j - goal_y)
    return distance

def get_blank_position(state):
    for i in range(3):
        for j in range(3):
            if state[i][j] == 0:
                return i, j

def move_tile(state, direction):
    """Generate successor state by moving blank"""
    x, y = get_blank_position(state)
    dx, dy = moves[direction]
    nx, ny = x + dx, y + dy
    
    if 0 <= nx < 3 and 0 <= ny < 3:
        new_state = [row[:] for row in state]
        new_state[x][y], new_state[nx][ny] = new_state[nx][ny], new_state[x][y]
        return new_state
    return None

def a_star(start):
    """A* Search Algorithm"""
    pq = []
    heappush(pq, (manhattan_distance(start), 0, start, []))
    visited = set()
    
    while pq:
        f, g, state, path = heappop(pq)
        state_tuple = tuple(flatten(state))
        
        if state == goal:
            return path
        
        if state_tuple in visited:
            continue
        visited.add(state_tuple)
        
        for move in moves:
            new_state = move_tile(state, move)
            if new_state:
                new_path = path + [move]
                g_new = g + 1
                f_new = g_new + manhattan_distance(new_state)
                heappush(pq, (f_new, g_new, new_state, new_path))
    
    return None

# EXAMPLE USAGE
start_state = [[2, 0, 3], [1, 5, 6], [4, 7, 8]]
if is_solvable(start_state):
    solution = a_star(start_state)
    print(f"Solution: {solution}")
    print(f"Moves: {len(solution)}")
```

### DFS Branch & Bound Implementation
```python
GOAL_STATE = [[1, 2, 3], [4, 5, 6], [7, 8, 0]]
MOVES = [(-1, 0), (1, 0), (0, -1), (0, 1)]

def find_blank(state):
    for i in range(3):
        for j in range(3):
            if state[i][j] == 0:
                return i, j
    return -1, -1

def successors(state):
    blank_i, blank_j = find_blank(state)
    for di, dj in MOVES:
        ni, nj = blank_i + di, blank_j + dj
        if 0 <= ni < 3 and 0 <= nj < 3:
            new_state = copy.deepcopy(state)
            new_state[blank_i][blank_j], new_state[ni][nj] = new_state[ni][nj], new_state[blank_i][blank_j]
            yield new_state

def is_goal(state):
    return state == GOAL_STATE

def state_to_tuple(state):
    return tuple(tuple(row) for row in state)

def dfbnb(start_state):
    """DFS Branch and Bound"""
    if not is_solvable(start_state):
        return None
    
    bound = float('inf')
    best_path = None
    stack = [(start_state, [], 0)]
    visited = dict()
    
    while stack:
        state, path, cost = stack.pop()
        state_t = state_to_tuple(state)
        heuristic = manhattan_distance(state)
        total_cost = cost + heuristic
        
        if total_cost >= bound:
            continue
        
        if (state_t in visited) and (visited[state_t] <= cost):
            continue
        visited[state_t] = cost
        
        if is_goal(state):
            bound = cost
            best_path = path + [state]
            continue
        
        for succ in successors(state):
            stack.append((succ, path + [state], cost + 1))
    
    return best_path
```

---

## ‚ôüÔ∏è 2. NIM GAME (MINIMAX & ALPHA-BETA PRUNING)

### Game Rules
- Heaps of stones: e.g., `(3, 4, 5)`
- Players alternate removing stones from ONE heap
- Player who takes last stone WINS
- Terminal utility: +1 (MAX wins), -1 (MIN wins)

### Complete Minimax Implementation
```python
def is_terminal(state):
    """Check if game is over (all heaps empty)"""
    return all(h == 0 for h in state)

def get_moves(state):
    """Generate all possible moves"""
    moves = []
    for i, heap in enumerate(state):
        if heap > 0:
            for remove in range(1, heap + 1):
                new_state = list(state)
                new_state[i] -= remove
                moves.append(tuple(new_state))
    return moves

def minimax(state, maximizing_player=True):
    """Basic Minimax Algorithm"""
    if is_terminal(state):
        return -1 if maximizing_player else 1
    
    if maximizing_player:
        value = float('-inf')
        for move in get_moves(state):
            child_val = minimax(move, False)
            value = max(value, child_val)
        return value
    else:
        value = float('inf')
        for move in get_moves(state):
            child_val = minimax(move, True)
            value = min(value, child_val)
        return value

def find_best_move_minimax(initial_state):
    """Find optimal move using minimax"""
    best_val = float('-inf')
    best_move = None
    for succ in get_moves(initial_state):
        val = minimax(succ, False)
        if val > best_val:
            best_val = val
            best_move = succ
    return best_move, best_val
```

### Alpha-Beta Pruning Implementation
```python
stats = {"visited": 0, "cutoffs": 0}

def alpha_beta(state, is_max, alpha, beta):
    """Alpha-Beta Pruning Algorithm"""
    stats["visited"] += 1
    
    if is_terminal(state):
        return -1 if is_max else 1
    
    if is_max:
        best_val = float('-inf')
        for child in get_moves(state):
            score = alpha_beta(child, False, alpha, beta)
            best_val = max(best_val, score)
            alpha = max(alpha, best_val)
            if alpha >= beta:  # Beta cutoff
                stats["cutoffs"] += 1
                break
        return best_val
    else:
        best_val = float('inf')
        for child in get_moves(state):
            score = alpha_beta(child, True, alpha, beta)
            best_val = min(best_val, score)
            beta = min(beta, best_val)
            if alpha >= beta:  # Alpha cutoff
                stats["cutoffs"] += 1
                break
        return best_val

def find_best_move_alphabeta(initial_state):
    """Find optimal move with alpha-beta"""
    best_val = float('-inf')
    best_move = None
    alpha = float('-inf')
    beta = float('inf')
    
    for succ in get_moves(initial_state):
        val = alpha_beta(succ, False, alpha, beta)
        if val > best_val:
            best_val = val
            best_move = succ
        alpha = max(alpha, best_val)
    
    return best_move, best_val

# EXAMPLE USAGE
initial = (3, 4, 5)
stats["visited"] = 0
stats["cutoffs"] = 0
move, score = find_best_move_alphabeta(initial)
print(f"Best move: {initial} -> {move}")
print(f"Score: {score}")
print(f"Nodes visited: {stats['visited']}")
print(f"Cutoffs: {stats['cutoffs']}")
```

### Minimax with Tree Visualization
```python
def minimax_with_graph(state, maximizing=True, graph=None, parent=None, best_path=None):
    """Minimax with networkx graph construction"""
    if graph is None:
        graph = nx.DiGraph()
    if best_path is None:
        best_path = {}
    
    node_label = str(state)
    if parent is not None:
        graph.add_edge(str(parent), node_label)
    
    if is_terminal(state):
        value = -1 if maximizing else 1
        graph.nodes[node_label]["label"] = f"{state}\nVal={value}"
        return value, graph, best_path
    
    if maximizing:
        value = float('-inf')
        best_child = None
        for move in get_moves(state):
            child_val, graph, best_path = minimax_with_graph(move, False, graph, state, best_path)
            if child_val > value:
                value = child_val
                best_child = move
        graph.nodes[node_label]["label"] = f"{state}\nMAX={value}"
        if best_child:
            best_path[state] = best_child
        return value, graph, best_path
    else:
        value = float('inf')
        best_child = None
        for move in get_moves(state):
            child_val, graph, best_path = minimax_with_graph(move, True, graph, state, best_path)
            if child_val < value:
                value = child_val
                best_child = move
        graph.nodes[node_label]["label"] = f"{state}\nMIN={value}"
        if best_child:
            best_path[state] = best_child
        return value, graph, best_path

def draw_tree(graph, best_path, root):
    """Visualize game tree"""
    pos = nx.spring_layout(graph, seed=42)
    labels = nx.get_node_attributes(graph, "label")
    
    path_edges = []
    current = root
    while current in best_path:
        nxt = best_path[current]
        path_edges.append((str(current), str(nxt)))
        current = nxt
    
    plt.figure(figsize=(12, 8))
    nx.draw(graph, pos, with_labels=False, node_size=2000, 
            node_color="lightblue", edge_color="gray")
    nx.draw_networkx_labels(graph, pos, labels, font_size=8)
    nx.draw_networkx_edges(graph, pos, edgelist=path_edges, 
                           edge_color="red", width=2)
    plt.title("Minimax Tree with Best Path")
    plt.show()
```

---

## ‚ôõ 3. N-QUEENS PROBLEM (LOCAL SEARCH)

### Problem Representation
- Board: list of N integers `[q1, q2, ..., qN]`
- `board[col] = row` means queen in column `col` is at row `row`
- Goal: 0 conflicts (no two queens attack each other)

### Min-Conflicts with Random Restart
```python
N = 8  # Board size

def count_conflicts(board):
    """Count attacking pairs"""
    conflicts = 0
    for i in range(N):
        for j in range(i + 1, N):
            same_row = (board[i] == board[j])
            same_diag = (abs(board[i] - board[j]) == abs(i - j))
            if same_row or same_diag:
                conflicts += 1
    return conflicts

def min_conflict_step(board):
    """Move one queen to minimize conflicts"""
    col = random.randint(0, N - 1)
    best_row = board[col]
    best_conflict = count_conflicts(board)
    
    for row in range(N):
        if row == board[col]:
            continue
        new_board = board[:]
        new_board[col] = row
        current_conflict = count_conflicts(new_board)
        if current_conflict < best_conflict:
            best_conflict = current_conflict
            best_row = row
    
    board[col] = best_row
    return board, best_conflict

def solve_nqueens(initial_board=None, max_steps=500):
    """Gradient descent with random restart"""
    attempts = 0
    while True:
        attempts += 1
        
        if initial_board is None:
            board = [random.randint(0, N - 1) for _ in range(N)]
        else:
            board = initial_board[:]
        
        conflicts = count_conflicts(board)
        print(f"Restart {attempts}: conflicts={conflicts}, board={board}")
        
        steps = 0
        while steps < max_steps:
            if conflicts == 0:
                print(f"‚úì Solution found in {steps} steps, {attempts} restarts")
                return board
            
            board, new_conflicts = min_conflict_step(board)
            
            if new_conflicts == conflicts:
                print(f"Stuck at local minimum (conflicts={conflicts})")
                break
            
            conflicts = new_conflicts
            steps += 1

def print_board(board):
    """Visualize board"""
    for row in range(N):
        line = []
        for col in range(N):
            line.append('Q' if board[col] == row else '.')
        print(' '.join(line))

# EXAMPLE USAGE
solution = solve_nqueens()
print("\nSolution:", solution)
print_board(solution)
```

### Matrix ‚Üî List Conversion
```python
def matrix_to_list(matrix):
    """Convert 2D board to 1D list"""
    board = [-1] * N
    for r in range(N):
        for c in range(N):
            if matrix[r][c] == 1:
                board[c] = r
    return board

def list_to_matrix(board):
    """Convert 1D list to 2D board"""
    matrix = [[0 for _ in range(N)] for _ in range(N)]
    for c, r in enumerate(board):
        matrix[r][c] = 1
    return matrix
```

---

## üå°Ô∏è 4. SIMULATED ANNEALING (8-QUEENS)

### Complete Implementation
```python
def cost(state):
    """Count attacking pairs"""
    c = 0
    n = len(state)
    for i in range(n):
        for j in range(i+1, n):
            if state[i] == state[j] or abs(state[i] - state[j]) == abs(i - j):
                c += 1
    return c

def neighbor(state):
    """Generate neighboring state"""
    n = len(state)
    # 20% chance: swap two columns
    if random.random() < 0.2:
        i, j = random.sample(range(n), 2)
        new_state = state[:]
        new_state[i], new_state[j] = new_state[j], new_state[i]
        return new_state
    # 80% chance: move one queen
    i = random.randrange(n)
    r = random.randrange(1, n + 1)
    while r == state[i]:
        r = random.randrange(1, n + 1)
    new_state = state[:]
    new_state[i] = r
    return new_state

def simulated_annealing(n=8, seed=None):
    """Simulated Annealing Algorithm"""
    if seed is not None:
        random.seed(seed)
    
    # Random initial state
    state = [random.randrange(1, n + 1) for _ in range(n)]
    energy = cost(state)
    best = state[:]
    best_e = energy
    
    # Temperature parameters
    T = 10.0
    T_min = 1e-4
    alpha = 0.995  # Cooling rate
    
    it = 0
    max_it = 200000
    
    while T > T_min and energy > 0 and it < max_it:
        it += 1
        new_state = neighbor(state)
        new_energy = cost(new_state)
        
        # Accept if better OR with probability exp(-(new-old)/T)
        if new_energy < energy or random.random() < math.exp((energy - new_energy) / T):
            state, energy = new_state, new_energy
            if energy < best_e:
                best, best_e = state[:], energy
        
        T *= alpha  # Cool down
    
    return best, best_e, it

def print_board_sa(state):
    """Print board (rows 1-N)"""
    n = len(state)
    for r in range(1, n + 1):
        line = []
        for c in range(n):
            line.append('Q' if state[c] == r else '.')
        print(' '.join(line))

# EXAMPLE USAGE
solution, conflicts, iterations = simulated_annealing(8)
print(f"Solution: {solution}")
print(f"Conflicts: {conflicts}")
print(f"Iterations: {iterations}")
print_board_sa(solution)
```

### Key Parameters to Adjust
```python
# Temperature schedule
T_initial = 10.0        # Starting temperature
T_min = 1e-4           # Stopping temperature
alpha = 0.995          # Cooling rate (0.9-0.999)

# Acceptance probability
P = exp((E_old - E_new) / T)  # Accept worse move with this probability
```

---

## üîÑ 5. HAMILTONIAN CYCLE PROBLEM

### TSP with A* Search
```python
def prims_mst(graph, nodes):
    """Prim's MST for heuristic estimation"""
    if not nodes:
        return 0
    
    start = next(iter(nodes))
    visited = {start}
    min_edges = [(w, start, nb) for nb, w in graph[start] if nb in nodes]
    heapq.heapify(min_edges)
    cost = 0
    
    while min_edges and len(visited) < len(nodes):
        w, u, v = heapq.heappop(min_edges)
        if v in visited:
            continue
        visited.add(v)
        cost += w
        for nb, wt in graph[v]:
            if nb in nodes and nb not in visited:
                heapq.heappush(min_edges, (wt, v, nb))
    
    return cost if len(visited) == len(nodes) else math.inf

def tsp_astar(graph, start_node):
    """TSP using A* with MST heuristic"""
    all_nodes = list(graph.keys())
    node_index = {v: i for i, v in enumerate(all_nodes)}
    n = len(all_nodes)
    
    def mask(v):
        return 1 << node_index[v]
    
    all_mask = (1 << n) - 1
    start_mask = mask(start_node)
    
    frontier = [(0, 0, start_node, start_mask, [start_node])]
    best_cost = {}
    
    while frontier:
        f, g, u, state, path = heapq.heappop(frontier)
        
        # All nodes visited - try to return to start
        if state == all_mask:
            for nb, w in graph[u]:
                if nb == start_node:
                    return path + [start_node]
            continue
        
        if (u, state) in best_cost and best_cost[(u, state)] <= g:
            continue
        best_cost[(u, state)] = g
        
        for nb, w in graph[u]:
            if state & mask(nb):
                continue
            new_state = state | mask(nb)
            new_g = g + w
            remaining = {v for v in all_nodes if not (new_state & mask(v))}
            heuristic = prims_mst(graph, remaining | {start_node, nb})
            heapq.heappush(frontier, (new_g + heuristic, new_g, nb, new_state, path + [nb]))
    
    return None

# EXAMPLE GRAPH
graph = {
    'A': [('B', 2), ('C', 9), ('D', 10)],
    'B': [('A', 2), ('C', 6), ('D', 4)],
    'C': [('A', 9), ('B', 6), ('D', 3)],
    'D': [('A', 10), ('B', 4), ('C', 3)]
}

cycle = tsp_astar(graph, 'A')
print("Hamiltonian Cycle:", cycle)
```

### Branch and Bound TSP
```python
def tsp_branch_bound(graph, start):
    """TSP using Branch & Bound"""
    n = len(graph)
    best = {"cost": math.inf, "path": []}
    
    # Precompute minimum outgoing edge for each node
    min_edge = [min(w for _, w in graph[v]) for v in range(n)]
    
    def dfs(path, visited, curr_cost):
        u = path[-1]
        
        # Lower bound estimate
        est = curr_cost + sum(min_edge[v] for v in range(n) if v not in visited)
        if est >= best["cost"]:
            return  # Prune
        
        # All nodes visited
        if len(path) == n:
            for nb, w in graph[u]:
                if nb == start:
                    total = curr_cost + w
                    if total < best["cost"]:
                        best["cost"] = total
                        best["path"] = path + [start]
            return
        
        # Explore neighbors
        for nb, w in graph[u]:
            if nb not in visited:
                dfs(path + [nb], visited | {nb}, curr_cost + w)
    
    dfs([start], {start}, 0)
    return (best["path"], best["cost"]) if best["cost"] < math.inf else (None, math.inf)

# EXAMPLE GRAPH (indexed)
graph = {
    0: [(1, 10), (2, 15), (3, 20)],
    1: [(0, 10), (2, 35), (3, 25)],
    2: [(0, 15), (1, 35), (3, 30)],
    3: [(0, 20), (1, 25), (2, 30)]
}

tour, cost = tsp_branch_bound(graph, 0)
print("Optimal cycle:", tour)
print("Cost:", cost)
```

---

## üó∫Ô∏è 6. MAP COLORING PROBLEM (CSP)

### Problem Statement
- **Variables**: States/regions to color
- **Domain**: Available colors (Red, Green, Blue, Yellow)
- **Constraints**: No two adjacent regions same color

### India Map Data Structure
```python
# 29 States
states = [
    "AP", "AR", "AS", "BR", "CG", "GA", "GJ", "HR", "HP", "JH", "KA", "KL",
    "MP", "MH", "MN", "ML", "MZ", "NL", "OD", "PB", "RJ", "SK", "TN", "TS",
    "TR", "UP", "UK", "WB", "JK"
]

# 4 Colors
colors = ["Red", "Green", "Blue", "Yellow"]

# Adjacency List
adjacency = {
    "AP": ["TS", "OD", "TN", "KA"],
    "AR": ["AS", "NL"],
    "AS": ["AR", "NL", "ML", "TR", "MZ", "MN", "WB"],
    "BR": ["UP", "JH", "WB"],
    "CG": ["UP", "JH", "OD", "MH"],
    "GA": ["MH", "KA"],
    "GJ": ["MH", "RJ"],
    "HR": ["PB", "HP", "UK", "RJ"],
    "HP": ["JK", "PB", "HR", "UK"],
    "JH": ["BR", "UP", "CG", "OD", "WB"],
    "KA": ["MH", "AP", "TS", "TN", "KL", "GA"],
    "KL": ["KA", "TN"],
    "MP": ["RJ", "UP", "CG", "MH", "GJ"],
    "MH": ["GJ", "MP", "CG", "TS", "KA", "GA"],
    "MN": ["AS", "MZ", "NL"],
    "ML": ["AS", "TR"],
    "MZ": ["AS", "MN", "TR"],
    "NL": ["AR", "AS", "MN"],
    "OD": ["WB", "JH", "CG", "AP", "TS"],
    "PB": ["JK", "HP", "HR", "RJ"],
    "RJ": ["PB", "HR", "MP", "GJ", "UP"],
    "SK": ["WB"],
    "TN": ["AP", "KA", "KL"],
    "TS": ["MH", "KA", "AP", "OD"],
    "TR": ["AS", "ML", "MZ"],
    "UP": ["UK", "HR", "RJ", "MP", "CG", "JH", "BR"],
    "UK": ["HP", "HR", "UP"],
    "WB": ["BR", "JH", "OD", "AS", "SK"],
    "JK": ["PB", "HP"]
}

def is_valid(state, color, assignment):
    """Check if assigning color to state is valid"""
    for neighbor in adjacency[state]:
        if neighbor in assignment and assignment[neighbor] == color:
            return False
    return True
```

### 1. Plain Backtracking
```python
def backtracking(assignment, steps):
    """Basic backtracking - no heuristics"""
    if len(assignment) == len(states):
        return assignment, steps
    
    # Select first unassigned variable
    var = [s for s in states if s not in assignment][0]
    
    for color in colors:
        steps[0] += 1
        if is_valid(var, color, assignment):
            assignment[var] = color
            result, steps = backtracking(assignment, steps)
            if result is not None:
                return result, steps
            del assignment[var]
    
    return None, steps

# USAGE
solution, steps = backtracking({}, [0])
print(f"Steps: {steps[0]}")
print(f"Solution: {solution}")
```

### 2. Backtracking with MRV + LCV Heuristics
```python
import copy

def mrv(assignment, domains):
    """Minimum Remaining Values - choose variable with smallest domain"""
    unassigned = [v for v in states if v not in assignment]
    return min(unassigned, key=lambda var: len(domains[var]))

def lcv(var, assignment, domains):
    """Least Constraining Value - order colors by constraint count"""
    counts = {}
    for color in domains[var]:
        count = 0
        for neighbor in adjacency[var]:
            if neighbor not in assignment and color in domains[neighbor]:
                count += 1
        counts[color] = count
    return sorted(domains[var], key=lambda c: counts[c])

def backtracking_mrv_lcv(assignment, domains, steps, verbose=True):
    """Backtracking with MRV + LCV heuristics"""
    if len(assignment) == len(states):
        return assignment, steps
    
    var = mrv(assignment, domains)
    if verbose:
        print(f"MRV chose: {var}, domain: {domains[var]}")
    
    for color in lcv(var, assignment, domains):
        if verbose:
            print(f"  Trying {color} for {var}")
        steps[0] += 1
        
        if is_valid(var, color, assignment):
            assignment[var] = color
            saved_domains = copy.deepcopy(domains)
            
            # Update neighbor domains
            for neighbor in adjacency[var]:
                if color in domains[neighbor]:
                    domains[neighbor].remove(color)
            
            result, steps = backtracking_mrv_lcv(assignment, domains, steps, verbose)
            if result is not None:
                return result, steps
            
            assignment.pop(var)
            domains = saved_domains
    
    return None, steps

# USAGE
domains = {s: colors[:] for s in states}
solution, steps = backtracking_mrv_lcv({}, domains, [0], verbose=False)
print(f"Steps: {steps[0]}")
```

### 3. Backtracking with MRV + LCV + AC-3
```python
from collections import deque

def revise(domains, xi, xj):
    """Remove inconsistent values from domain of xi"""
    revised = False
    for x in domains[xi][:]:
        # If all values in xj's domain conflict with x, remove x
        if all(x == y for y in domains[xj]):
            domains[xi].remove(x)
            revised = True
    return revised

def ac3(domains):
    """AC-3 Algorithm - Arc Consistency"""
    queue = deque([(xi, xj) for xi in states for xj in adjacency[xi]])
    
    while queue:
        xi, xj = queue.popleft()
        if revise(domains, xi, xj):
            if not domains[xi]:
                return False  # Domain wipe-out
            for xk in adjacency[xi]:
                if xk != xj:
                    queue.append((xk, xi))
    return True

def backtracking_ac3(assignment, domains, steps, verbose=True):
    """Backtracking with MRV + LCV + AC-3"""
    if len(assignment) == len(states):
        return assignment, steps
    
    var = mrv(assignment, domains)
    if verbose:
        print(f"MRV chose: {var}, domain: {domains[var]}")
    
    for color in lcv(var, assignment, domains):
        if verbose:
            print(f"  Trying {color} for {var}")
        steps[0] += 1
        
        if is_valid(var, color, assignment):
            assignment[var] = color
            saved_domains = copy.deepcopy(domains)
            
            # Update neighbor domains
            for neighbor in adjacency[var]:
                if color in domains[neighbor]:
                    domains[neighbor].remove(color)
            
            # Apply AC-3 for constraint propagation
            if ac3(domains):
                result, steps = backtracking_ac3(assignment, domains, steps, verbose)
                if result is not None:
                    return result, steps
            
            assignment.pop(var)
            domains = saved_domains
    
    return None, steps

# USAGE
domains = {s: colors[:] for s in states}
solution, steps = backtracking_ac3({}, domains, [0], verbose=False)
print(f"Steps: {steps[0]}")
```

### Comparison Template
```python
import time
import pandas as pd

results = []

# 1. Plain Backtracking
print("--- Plain Backtracking ---")
start = time.time()
solution1, steps1 = backtracking({}, [0])
elapsed1 = time.time() - start
results.append(["Plain Backtracking", steps1[0], elapsed1])
print(f"Steps: {steps1[0]}, Time: {elapsed1:.5f}s")

# 2. MRV + LCV
print("\n--- Backtracking + MRV + LCV ---")
domains = {s: colors[:] for s in states}
start = time.time()
solution2, steps2 = backtracking_mrv_lcv({}, domains, [0], verbose=False)
elapsed2 = time.time() - start
results.append(["MRV + LCV", steps2[0], elapsed2])
print(f"Steps: {steps2[0]}, Time: {elapsed2:.5f}s")

# 3. MRV + LCV + AC-3
print("\n--- Backtracking + MRV + LCV + AC-3 ---")
domains = {s: colors[:] for s in states}
start = time.time()
solution3, steps3 = backtracking_ac3({}, domains, [0], verbose=False)
elapsed3 = time.time() - start
results.append(["MRV + LCV + AC-3", steps3[0], elapsed3])
print(f"Steps: {steps3[0]}, Time: {elapsed3:.5f}s")

# Print comparison table
df = pd.DataFrame(results, columns=["Algorithm", "Steps", "Time (s)"])
print("\n--- Comparison Table ---")
print(df)
```

### Visualization (Optional)
```python
import matplotlib.pyplot as plt

color_map = {"Red": "red", "Green": "green", "Blue": "blue", "Yellow": "yellow"}

def draw_graph(solution, title):
    """Visualize colored map"""
    # Create positions (simple grid layout)
    pos = {s: (i % 10, -(i // 10)) for i, s in enumerate(states)}
    
    plt.figure(figsize=(12, 8))
    
    # Draw edges (adjacencies)
    for state in adjacency:
        for neighbor in adjacency[state]:
            x1, y1 = pos[state]
            x2, y2 = pos[neighbor]
            plt.plot([x1, x2], [y1, y2], color="gray", linewidth=1, zorder=1)
    
    # Draw nodes (states)
    for state, (x, y) in pos.items():
        c = color_map[solution[state]]
        plt.scatter(x, y, s=500, c=c, edgecolors="black", linewidth=2, zorder=2)
        plt.text(x, y, state, ha="center", va="center", 
                fontsize=9, weight="bold", zorder=3)
    
    plt.title(title, fontsize=14, weight="bold")
    plt.axis("off")
    plt.tight_layout()
    plt.show()

# Usage
draw_graph(solution1, "India Map - Plain Backtracking")
```

### CSP Key Concepts

**MRV (Minimum Remaining Values)**
- Select variable with fewest legal values left
- Fails faster, reducing search tree
- Also called "most constrained variable"

**LCV (Least Constraining Value)**
- Try value that rules out fewest choices for neighbors
- Leaves maximum flexibility for future assignments
- Maximizes chances of finding solution

**AC-3 (Arc Consistency Algorithm)**
- Enforces arc consistency between variables
- Removes values that can't be part of any solution
- Propagates constraints through the graph
- Reduces domains before search begins

### Algorithm Complexity Comparison

```python
# Expected Performance (India Map, 29 states, 4 colors)
# Plain Backtracking:       ~100-500 steps
# MRV + LCV:               ~40-80 steps  (50-70% reduction)
# MRV + LCV + AC-3:        ~30-50 steps  (70-85% reduction)
```

### Why AC-3 is Most Efficient

1. **Early Failure Detection**: Identifies dead-ends before exploring
2. **Domain Reduction**: Shrinks search space dramatically
3. **Constraint Propagation**: One assignment triggers cascading eliminations
4. **Prevents Backtracking**: Stops invalid paths early

---

## üéØ QUICK REFERENCE FORMULAS

### Heuristics
```python
# Manhattan Distance (8-Puzzle)
h = sum(|current_x - goal_x| + |current_y - goal_y|)

# Misplaced Tiles
h = count of tiles not in goal position

# Conflicts (N-Queens)
h = number of attacking queen pairs
```

### Search Algorithms
```python
# A*: f(n) = g(n) + h(n)
# g(n) = actual cost from start
# h(n) = heuristic estimate to goal

# Minimax Value
V(s) = max over children of min(child values)  # MAX's turn
V(s) = min over children of max(child values)  # MIN's turn

# Alpha-Beta Pruning
# Prune when: alpha >= beta
# alpha = best value for MAX so far
# beta = best value for MIN so far

# Simulated Annealing Acceptance
if new_cost < current_cost:
    accept
else:
    accept with probability = exp((current - new) / T)
```

---

## üîß COMMON MODIFICATIONS FOR EXAM

### Change Initial State
```python
# 8-Puzzle
start = [[7, 2, 3], [5, 0, 6], [4, 1, 8]]  # Change this

# Nim Game
initial = (5, 7, 9)  # Change heap sizes

# N-Queens
N = 10  # Change board size
```

### Change Goal State
```python
# Custom 8-Puzzle Goal
goal = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]  # 0 at top-left

# Adjust divmod calculation in manhattan_distance accordingly
```

### Change Heuristic
```python
# Misplaced tiles instead of Manhattan
def misplaced_tiles(state):
    count = 0
    for i in range(3):
        for j in range(3):
            if state[i][j] != 0 and state[i][j] != goal[i][j]:
                count += 1
    return count
```

### Change Game Rules (Nim)
```python
# Mis√®re Nim (last player LOSES)
def evaluate(position, is_max_turn):
    if is_max_turn:
        return 1  # Reversed!
    return -1
```

### Change Temperature Schedule
```python
# Linear cooling
T = T - delta

# Geometric cooling (most common)
T = T * alpha

# Logarithmic cooling
T = T0 / log(1 + iteration)
```

---

## üêõ DEBUGGING TIPS

### Print States During Search
```python
# Add to A*
print(f"Exploring: {state}, g={g}, h={h}, f={f}")

# Add to Minimax
print(f"{'MAX' if maximizing else 'MIN'} at {state}, value={value}")

# Add to Simulated Annealing
print(f"T={T:.4f}, E={energy}, accepted={accepted}")
```

### Check Solvability
```python
# Always check before solving 8-Puzzle
if not is_solvable(start):
    print("Unsolvable puzzle!")
    exit()
```

### Visualize Solutions
```python
# Print path step-by-step
def print_solution_path(path):
    for i, state in enumerate(path):
        print(f"Step {i}:")
        for row in state:
            print(row)
        print()
```

---

## ‚ö° PERFORMANCE TIPS

### Use Tuples for Hashing
```python
# Convert list to tuple for set/dict
state_tuple = tuple(tuple(row) for row in state)
visited.add(state_tuple)
```

### Early Termination
```python
# Stop when solution found
if conflicts == 0:
    return solution

# Bound checking in Branch & Bound
if estimate >= best_known:
    return  # Prune this branch
```

### Limit Iterations
```python
max_steps = 500
max_restarts = 100
timeout = 60  # seconds
```

---

## üìù EXAM STRATEGY

1. **Read problem carefully** - note any changes from standard version
2. **Check initial/goal states** - they might be different
3. **Identify algorithm** - A*, minimax, local search, etc.
4. **Copy base template** - use this cheatsheet
5. **Modify parameters** - adjust for problem specifics
6. **Test with simple case** - use small input first
7. **Add print statements** - debug if needed
8. **Verify output format** - match expected output

### Common Exam Patterns
- Change puzzle size (3x3 ‚Üí 4x4)
- Change game rules (nim ‚Üí custom)
- Change initial state
- Change heuristic function
- Add visualization requirement
- Compare algorithms (minimax vs alpha-beta)
- Modify acceptance criteria (simulated annealing)
- **Change map/graph** (India ‚Üí Australia, USA, etc.)
- **Change number of colors** (3 colors, 5 colors)
- **Add/remove CSP constraints**
- **Compare CSP approaches** (Plain vs MRV+LCV vs AC-3)

### Map Coloring Quick Modifications

```python
# Change to different map (e.g., Australia)
states = ["WA", "NT", "SA", "Q", "NSW", "V", "T"]
adjacency = {
    "WA": ["NT", "SA"],
    "NT": ["WA", "SA", "Q"],
    "SA": ["WA", "NT", "Q", "NSW", "V"],
    "Q": ["NT", "SA", "NSW"],
    "NSW": ["Q", "SA", "V"],
    "V": ["SA", "NSW"],
    "T": []  # Tasmania - no neighbors
}

# Change number of colors
colors = ["Red", "Green", "Blue"]  # 3 colors
colors = ["Red", "Green", "Blue", "Yellow", "Orange"]  # 5 colors

# Change to different problem (e.g., course scheduling)
variables = ["CS101", "CS102", "MATH201", "PHY101"]
domains = {
    "CS101": ["9AM", "10AM", "11AM"],
    "CS102": ["9AM", "10AM", "11AM"],
    # ... etc
}
constraints = {
    "CS101": ["CS102"],  # Can't be same time
    # ... etc
}
```

---

## ‚úÖ FINAL CHECKLIST

Before submitting:
- [ ] All imports included
- [ ] Function names match requirements
- [ ] Output format correct
- [ ] Handles edge cases
- [ ] No syntax errors
- [ ] Tested with sample input
- [ ] Comments added (if required)

Good luck! üçÄ